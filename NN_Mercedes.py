# -*- coding: utf-8 -*-
"""NN Mercedes

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1hizyc49mkGAWqPkJOHOoq43aC3cizi5F

ЕГОРОВ Д.А.
____
18-АС
____
2 ВАРИАНТ

ПОДКЛЮЧЕНИЕ ВСЕХ НЕОБХОДИМЫХ ЗАВИСИМОСТЕЙ
"""

!pip install -U keras-tuner
!pip install -U pygal

import pandas as pd
import numpy as np
import random
import pygal
from keras.datasets import boston_housing
from keras.models import Sequential
from keras.layers import Dense, MaxPooling2D, Conv2D, Flatten
from keras.optimizers import SGD
from kerastuner.tuners import RandomSearch, Hyperband, BayesianOptimization
from kerastuner.engine import hyperparameters
from keras.layers import Dropout
from keras import backend as K
from keras.regularizers import L1, L2
from sklearn import preprocessing
from sklearn.model_selection import train_test_split
from sklearn.impute import SimpleImputer
import time
import math
import seaborn as sns
import matplotlib.pyplot as plt
from keras import utils
from sklearn.preprocessing import MinMaxScaler

"""ЧТЕНИЕ И ВЫВОД ИСХОДНЫХ ДАННЫХ"""

TRAIN_FILE_PATH = '/content/drive/My Drive/train.csv'

# загружаем данные
x = pd.read_csv(TRAIN_FILE_PATH) 

x

"""ПОЛУЧЕНИЕ ВЕРНЫХ ОТВЕТОВ"""

y = x.get('y')

"""УДАЛЕНИЕ ЛИШНИХ СТОЛБЦОВ"""

x.drop('y', axis='columns', inplace=True)
x.drop('ID', axis='columns', inplace=True)
x.head()

"""НАХОЖДЕНИЕ ВСЕХ СТОЛБЦОВ, В КОТОРЫХ НЕНУЛЕВОЕ ЗНАЧЕНИЕ ИМЕЕТСЯ ТОЛЬКО В ПЕРВОЙ СТРОКЕ"""

suspicious_data = []
for col in x:
    if len(x[col].unique()) == 1:
        suspicious_data.append(col)
x[suspicious_data].describe()

"""УДАЛЕНИЕ ВСЕХ ТАКИХ СТОЛБЦОВ"""

x.drop(suspicious_data, 1, inplace = True)

"""ПОЛУЧЕНИЕ СПИСКА ПРИЗНАКОВ, ЗАШИФРОВАННЫХ БУКВЕННО"""

cat_vars = [var for var in x.columns if x[var].dtypes == 'O']
print('Number of categorical variables: ', len(cat_vars))

x[cat_vars]

"""КАТЕГОРИАЛЬНЫЕ ПРИЗНАКИ ШИФРУЮТСЯ ЧЕРЕЗ LABEL ENCODER В ЧИСЛА"""

df = pd.DataFrame(x[cat_vars])
x[cat_vars] = df.apply(preprocessing.LabelEncoder().fit_transform)

x[cat_vars]

"""НОРМАЛИЗАЦИЯ ДАННЫХ"""

scaler = MinMaxScaler()
x[cat_vars] = scaler.fit_transform(x[cat_vars])

x

"""ПРОВЕРКА НА НАЛИЧИЕ NaN"""

def check_nans(data):
  nan_cols = []
  for col_name, col_info in data.items():
    for line_number, line_info in col_info.items():
      if math.isnan(line_info):
        print(f"{col_name } is NaNs")
        nan_cols.append(col_name)
        break
  if nan_cols == []:
    print("[INFO] THERE IS NO NaNS IN DATA!")
  return nan_cols

nan_cols = check_nans(x)

"""ДЕЛЕНИЕ ДАННЫХ НА ТРЕНИРОВОЧНЫЕ И ПРОВЕРОЧНЫЕ"""

x_train, x_test, y_train, y_test = train_test_split(x, y, random_state=0, test_size = 0.2)

"""СОЗДАНИЕ И ОБУЧЕНИЕ МОДЕЛИ ВРУЧНУЮ"""

model = Sequential()

model.add(Dense(512, activation='relu', input_shape=(x_train.shape[1],)))
model.add(Dropout(0.1))
model.add(Dense(256, activation='relu'))
model.add(Dense(128, activation='relu'))
model.add(Dense(1))


model.compile(loss='mse', optimizer='adam', metrics=['mae'])
model.summary()
history = model.fit(x_train, y_train, epochs=100, batch_size=128, validation_split=0.2)
history = history.history

"""СОЗДАНИЕ ГРАФИКОВ"""

def draw_graph(history):
    loss_values = history["loss"]
    validation_loss_values = history["val_loss"]

    epochs = range(1, len(history['loss']) + 1)

    plt.plot(epochs, loss_values, 'b', label='Training loss')
    plt.plot(epochs, validation_loss_values, 'r', label='Validation loss')
    plt.title('Training and validation loss')
    plt.xlabel('Epochs')
    plt.ylabel('Value')
    plt.legend()
    plt.show()

draw_graph(history)

"""ВЫЧИСЛЕНИЕ ОШИБКИ НА ТЕСТОВЫХ ДАННЫХ"""

print("[INFO] RUNNING ON TEST DATA: \n")
mse, mae = model.evaluate(x_test, y_test, verbose=0, batch_size=128)
print(f"[INFO] Mean squared error is {mse}")
print(f"[INFO] Mean absolute error is {mae}")

"""ФУНКЦИЯ СОЗДАНИЯ МОДЕЛИ"""

def build_model(hp):
  hidden_layers = hp.Choice('hidden_layers', values=[1,2,3])
  activation_choice = hp.Choice('activation', values=['relu', 'selu', 'elu'])
  model = Sequential()
  model.add(Dense(units=hp.Int('units',min_value=256,max_value=512,step=32),activation=activation_choice, input_shape=(x_train.shape[1], ), kernel_regularizer=L2(0.001)))
  model.add(Dropout(0.3))
  for i in range(hidden_layers):
    model.add(Dense(units=hp.Int(f'layer_{i}_units_',min_value=32//(i+1), max_value=128//(i+1),step=64//(i+1)),activation=activation_choice, kernel_regularizer=L2(0.001)))
  model.add(Dense(1))  
  model.compile(optimizer='rmsprop', loss="mse", metrics=["mae"])
  return model

"""1)      ПОИСК ЛУЧШЕЙ МОДЕЛИ С ПОМОЩЬЮ RANDOM_SEARCH"""

def find_best_NN(x_train, y_train):
  tuner = RandomSearch(build_model, objective="loss", max_trials=10, executions_per_trial=1)
  print("\n\n\n")
  print('[INFO] start searching')
  tuner.search(x_train, y_train, batch_size=100, epochs=10, validation_split=0.2)
  print("\n\n\nRESULTS SUMMARY")
  tuner.results_summary()
  print("\n\n\n")
  print("\n\n\nHERE IS THE BEST MODEL\n\n\n")
  best_params = tuner.get_best_hyperparameters()[0]
  best_model = tuner.hypermodel.build(best_params)
  best_model.summary()
  return best_model

best_model = find_best_NN(x_train, y_train)

"""2)  ПОИСК ЛУЧШЕЙ МОДЕЛИ С ПОМОЩЬЮ HYPER_BAND"""

def find_best_NN(x_train_main, y_train_main):
  tuner = Hyperband(build_model, objective="loss", max_epochs=10, hyperband_iterations=3)
  print("\n\n\n")
  print('[INFO] start searching')
  tuner.search(x_train, y_train, batch_size=128, epochs=10, validation_split=0.2)
  print("\n\n\nRESULTS SUMMARY")
  tuner.results_summary()
  print("\n\n\n")
  print("\n\n\nHERE IS THE BEST MODEL\n\n\n")
  best_params = tuner.get_best_hyperparameters()[0]
  best_model = tuner.hypermodel.build(best_params)
  best_model.summary()
  return best_model
  

best_model = find_best_NN(x_train, y_train)

"""УДАЛЕНИЕ ЛОГА ПОДБОРА МОДЕЛЕЙ"""

! rm -rf untitled_project/

"""ТРЕНИРОВКА НАИЛУЧШЕЙ МОДЕЛИ"""

best_history = best_model.fit(x_train, y_train, epochs=100, batch_size=128, validation_split=0.2)
best_history = best_history.history
print("[INFO] Training has been finished")

"""ГРАФИКИ ТРЕНИРОВКИ ЛУЧШЕЙ МОДЕЛИ"""

draw_graph(best_history)

"""ПРОВЕРКА ЛУЧШЕЙ МОДЕЛИ НА ТЕСТОВЫХ ДАННЫХ"""

print("[INFO] RUNNING ON TEST DATA: \n")
mse, mae = best_model.evaluate(x_test, y_test, verbose=1)
print(f"[INFO] Mean squared error is {mse}")
print(f"[INFO] Mean absolute error is {mae}")

"""ПРЕДСКАЗАНИЕ НА МОДЕЛИ, СОЗДАННОЙ ***ВРУЧНУЮ***"""

predicted_y = model.predict(x_test)

"""ПРЕДСКАЗАНИЕ НА МОДЕЛИ, СОЗДАННОЙ С ПОМОЩЬЮ ***ТЮНЕРА***"""

best_predicted_y = best_model.predict(x_test)

"""ПЕРЕВОДИМ В ВЕКТОРЫ ДЛЯ ПОДСЧЕТА КОРРЕЛЯЦИИ"""

predicted_y = np.reshape(predicted_y, (predicted_y.shape[0]))
best_predicted_y = np.reshape(best_predicted_y, (best_predicted_y.shape[0]))
y_test = np.reshape(y_test, (y_test.shape[0]))

"""ПОДСЧЕТ КОРРЕЛЯЦИИ С МОДЕЛЬЮ, СОЗДАННОЙ ***ТЮНЕРОМ***"""

best_cc = np.corrcoef(best_predicted_y, y_test)
best_cc = best_cc[0][1]
print(f'Correlation Coefficient: {best_cc}')

"""ПОДСЧЕТ КОРРЕЛЯЦИИ С МОДЕЛЬЮ, СОЗДАННОЙ ***ВРУЧНУЮ***"""

best_cc = np.corrcoef(predicted_y, y_test)
best_cc = best_cc[0][1]
print(f'Correlation Coefficient: {best_cc}')

"""ГРАФИКИ РАСПРЕДЕЛЕНИЯ ДЕЙСТВИТЕЛЬНЫХ И ПРЕДСКАЗАННЫХ ЗНАЧЕНИЙ Y МОДЕЛИ, СОЗДАННОЙ ***ТЮНЕРОМ***"""

sns.distplot(best_predicted_y)
sns.distplot(y)

"""НАГЛЯДНОЕ СРАВНЕНИЕ ДЕЙСТВИТЕЛЬНЫХ И ПРЕДСКАЗАННЫХ ЗНАЧЕНИЙ МОДЕЛИ, СОЗДАННОЙ ***ТЮНЕРОМ***"""

for real, pred in zip(y_test, best_predicted_y):
  print(f"[TRUE] {real} : {pred} [PREDICTED]")

"""ГРАФИК ЗАВИСИМОСТИ РЕАЛЬНЫХ ЗНАЧЕНИЙ ОТ ПРЕДСКАЗАННЫХ"""

plt.clf()
plt.figure(figsize = (20, 10))
plt.scatter(y_test, best_predicted_y, s = 40, color = 'blue')
plt.axes().get_xaxis().set_visible(True)
plt.axes().get_yaxis().set_visible(True)
plt.show()