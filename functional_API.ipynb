{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "functional_API",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r66kNaN9YdTK"
      },
      "source": [
        "# ГЛАВА 7"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FYLuRXpIYwCp"
      },
      "source": [
        "Создание модели привычным способом и с помощью API"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c5bykXnnYaED"
      },
      "source": [
        "# keras API позволяет напрямую манипулировать тензорами и \n",
        "# рассматривать слои как функции\n",
        "from keras.models import Sequential, Model\n",
        "from keras.layers import Dense\n",
        "from keras import Input\n",
        "import numpy as np\n",
        "\n",
        "# Привычный способ\n",
        "model = Sequential()\n",
        "model.add(Dense(128, activation='relu', input_shape=(64,)))\n",
        "model.add(Dense(64, activation='relu'))\n",
        "model.add(Dense(10, activation='softmax'))\n",
        "\n",
        "# Эквивалент через API\n",
        "# создаем входной тензор\n",
        "input_tensor = Input(shape=(64,))\n",
        "# в первый слой передаем входной тензор\n",
        "x = Dense(128, activation='relu')(input_tensor)\n",
        "# во второй слой передаем первый слой\n",
        "x = Dense(64, activation='relu')(x)\n",
        "# в каждый последующий слой передаем предыдущий\n",
        "output_tensor = Dense(10, activation='softmax')(x)\n",
        "\n",
        "# создаем модель, указывая входной и выходной тензоры\n",
        "model = Model(input_tensor, output_tensor)\n",
        "\n",
        "model.summary()\n",
        "\n",
        "# компиляция, обучение, оценка - такие же\n",
        "model.compile(\n",
        "    optimizer='rmsprop',\n",
        "    loss='categorical_crossentropy',\n",
        "    metrics=['mae']\n",
        ")\n",
        "\n",
        "x_train = np.random.random((1000,64))\n",
        "y_train = np.random.random((1000,10))\n",
        "\n",
        "model.fit(\n",
        "    x_train,\n",
        "    y_train,\n",
        "    batch_size=32,\n",
        "    epochs=20\n",
        ")\n",
        "\n",
        "score = model.evaluate(x_train, y_train)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4Q3j4PnAb_0V"
      },
      "source": [
        "Создание модели типа \"вопрос-ответ\" с несколькими входами"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Se2Be_IrcPyc",
        "outputId": "945404ee-d866-4b0c-91b0-3c21f937dc33",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# обычно модель \"вопрос-ответ\" получает на вход вопрос на естественном языке\n",
        "# и текст, на основе которого будет даваться ответ\n",
        "\n",
        "from keras.models import Model\n",
        "from keras import layers\n",
        "from keras import Input\n",
        "\n",
        "text_size = 10_000\n",
        "question_size = 10_000\n",
        "answer_size = 500\n",
        "\n",
        "# входной текст - последовательность целых чисел переменной длины\n",
        "# форма - (количество образцов, длина образца)\n",
        "text_input = Input(shape=(None,), dtype='int32', name='text')\n",
        "# преобразование текста в последовательность векторов размером 64\n",
        "embedded_text = layers.Embedding(text_size, 64)(text_input)\n",
        "# преобразование в единый вектор\n",
        "encoded_text = layers.LSTM(32)(embedded_text)\n",
        "\n",
        "question_input = Input(shape=(None,), dtype='float32', name='question')\n",
        "embedded_question = layers.Embedding(question_size, 64)(question_input)\n",
        "encoded_question = layers.LSTM(32)(embedded_question)\n",
        "\n",
        "# объединение закодированного вопроса и ответа\n",
        "concatenated = layers.concatenate([encoded_text, encoded_question], axis=-1)\n",
        "\n",
        "# создание классификатора\n",
        "answer = layers.Dense(answer_size, activation='softmax')(concatenated)\n",
        "\n",
        "model = Model([text_input, question_input], answer)\n",
        "\n",
        "model.compile(optimizer='rmsprop', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# ПЕРЕДАЧА ДАННЫХ В МОДЕЛЬ С НЕСКОЛЬКИМИ ВХОДАМИ\n",
        "num_samples = 1000\n",
        "max_length = 100\n",
        "\n",
        "text = np.random.randint(1, text_size, size=(num_samples, max_length))\n",
        "question = np.random.randint(1, question_size, size=(num_samples, max_length))\n",
        "answers = np.zeros(shape=(num_samples, answer_size))\n",
        "# массив индексов\n",
        "indices = np.random.randint(0, answer_size, size=num_samples)\n",
        "# прямое кодирование вопросов\n",
        "for i, x in enumerate(answers):\n",
        "  x[indices[i]] = 1\n",
        "\n",
        "# можно передать так\n",
        "model.fit([text, question], answers, epochs=20, batch_size=128)\n",
        "# но если при создании через Input тензорам давались имена, то можно передать и через словарь\n",
        "model.fit({'text':text, 'question':question}, answers, epochs=20, batch_size=128)\n",
        "\n",
        "model.evaluate([text, question], answers)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/20\n",
            "8/8 [==============================] - 0s 26ms/step - loss: 6.2145 - accuracy: 0.0020\n",
            "Epoch 2/20\n",
            "8/8 [==============================] - 0s 26ms/step - loss: 6.1890 - accuracy: 0.0330\n",
            "Epoch 3/20\n",
            "8/8 [==============================] - 0s 25ms/step - loss: 6.1026 - accuracy: 0.0040\n",
            "Epoch 4/20\n",
            "8/8 [==============================] - 0s 25ms/step - loss: 6.0131 - accuracy: 0.0030\n",
            "Epoch 5/20\n",
            "8/8 [==============================] - 0s 26ms/step - loss: 5.9218 - accuracy: 0.0050\n",
            "Epoch 6/20\n",
            "8/8 [==============================] - 0s 25ms/step - loss: 5.8282 - accuracy: 0.0130\n",
            "Epoch 7/20\n",
            "8/8 [==============================] - 0s 27ms/step - loss: 5.7401 - accuracy: 0.0230\n",
            "Epoch 8/20\n",
            "8/8 [==============================] - 0s 25ms/step - loss: 5.6365 - accuracy: 0.0270\n",
            "Epoch 9/20\n",
            "8/8 [==============================] - 0s 24ms/step - loss: 5.5529 - accuracy: 0.0370\n",
            "Epoch 10/20\n",
            "8/8 [==============================] - 0s 25ms/step - loss: 5.4571 - accuracy: 0.0290\n",
            "Epoch 11/20\n",
            "8/8 [==============================] - 0s 26ms/step - loss: 5.3751 - accuracy: 0.0440\n",
            "Epoch 12/20\n",
            "8/8 [==============================] - 0s 26ms/step - loss: 5.2961 - accuracy: 0.0460\n",
            "Epoch 13/20\n",
            "8/8 [==============================] - 0s 25ms/step - loss: 5.2131 - accuracy: 0.0590\n",
            "Epoch 14/20\n",
            "8/8 [==============================] - 0s 25ms/step - loss: 5.1345 - accuracy: 0.0800\n",
            "Epoch 15/20\n",
            "8/8 [==============================] - 0s 26ms/step - loss: 5.0606 - accuracy: 0.0950\n",
            "Epoch 16/20\n",
            "8/8 [==============================] - 0s 26ms/step - loss: 4.9850 - accuracy: 0.1110\n",
            "Epoch 17/20\n",
            "8/8 [==============================] - 0s 25ms/step - loss: 4.9174 - accuracy: 0.1080\n",
            "Epoch 18/20\n",
            "8/8 [==============================] - 0s 25ms/step - loss: 4.8568 - accuracy: 0.1260\n",
            "Epoch 19/20\n",
            "8/8 [==============================] - 0s 25ms/step - loss: 4.7626 - accuracy: 0.1490\n",
            "Epoch 20/20\n",
            "8/8 [==============================] - 0s 27ms/step - loss: 4.6943 - accuracy: 0.1710\n",
            "Epoch 1/20\n",
            "8/8 [==============================] - 0s 26ms/step - loss: 4.6726 - accuracy: 0.1660\n",
            "Epoch 2/20\n",
            "8/8 [==============================] - 0s 26ms/step - loss: 4.5443 - accuracy: 0.2020\n",
            "Epoch 3/20\n",
            "8/8 [==============================] - 0s 25ms/step - loss: 4.4749 - accuracy: 0.2230\n",
            "Epoch 4/20\n",
            "8/8 [==============================] - 0s 25ms/step - loss: 4.4189 - accuracy: 0.2340\n",
            "Epoch 5/20\n",
            "8/8 [==============================] - 0s 25ms/step - loss: 4.3646 - accuracy: 0.2640\n",
            "Epoch 6/20\n",
            "8/8 [==============================] - 0s 25ms/step - loss: 4.2458 - accuracy: 0.3040\n",
            "Epoch 7/20\n",
            "8/8 [==============================] - 0s 24ms/step - loss: 4.2108 - accuracy: 0.2960\n",
            "Epoch 8/20\n",
            "8/8 [==============================] - 0s 23ms/step - loss: 4.1243 - accuracy: 0.3220\n",
            "Epoch 9/20\n",
            "8/8 [==============================] - 0s 24ms/step - loss: 4.0611 - accuracy: 0.3340\n",
            "Epoch 10/20\n",
            "8/8 [==============================] - 0s 25ms/step - loss: 4.0353 - accuracy: 0.3500\n",
            "Epoch 11/20\n",
            "8/8 [==============================] - 0s 24ms/step - loss: 3.9883 - accuracy: 0.3900\n",
            "Epoch 12/20\n",
            "8/8 [==============================] - 0s 24ms/step - loss: 3.8628 - accuracy: 0.4100\n",
            "Epoch 13/20\n",
            "8/8 [==============================] - 0s 23ms/step - loss: 3.7939 - accuracy: 0.4350\n",
            "Epoch 14/20\n",
            "8/8 [==============================] - 0s 24ms/step - loss: 3.7154 - accuracy: 0.4470\n",
            "Epoch 15/20\n",
            "8/8 [==============================] - 0s 25ms/step - loss: 3.7002 - accuracy: 0.4500\n",
            "Epoch 16/20\n",
            "8/8 [==============================] - 0s 25ms/step - loss: 3.6132 - accuracy: 0.4750\n",
            "Epoch 17/20\n",
            "8/8 [==============================] - 0s 24ms/step - loss: 3.5210 - accuracy: 0.4900\n",
            "Epoch 18/20\n",
            "8/8 [==============================] - 0s 25ms/step - loss: 3.4557 - accuracy: 0.5100\n",
            "Epoch 19/20\n",
            "8/8 [==============================] - 0s 25ms/step - loss: 3.4141 - accuracy: 0.5200\n",
            "Epoch 20/20\n",
            "8/8 [==============================] - 0s 25ms/step - loss: 3.3503 - accuracy: 0.5450\n",
            "32/32 [==============================] - 0s 8ms/step - loss: 3.4386 - accuracy: 0.5130\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[3.438575267791748, 0.5130000114440918]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    }
  ]
}