{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "FeaturesVisualisation.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wad69urWtiE-"
      },
      "source": [
        "В этой части я займусь визуализацией знаний, который хранятся и обрабатываются в сверточной нейронной сети\n",
        "\n",
        "\n",
        "\n",
        "1.  карт признаков, выделенных слоями\n",
        "2.  фильтров слоев\n",
        "3.  тепловых карт\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OUgCl8N6t58t"
      },
      "source": [
        "# ЧАСТЬ 1: ВИЗУАЛИЗАЦИЯ ПРОМЕЖУТОЧНЫХ АКТИВАЦИЙ (КАРТ ПРИЗНАКОВ)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RmGulrG_uDLb"
      },
      "source": [
        "Загрузка ранее натренированной модели"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0nhMHIpKtPLM"
      },
      "source": [
        "from keras.models import load_model\n",
        "\n",
        "model = load_model('/content/drive/My Drive/StudyingKeras/Dogs_vs_Cats/weights/cats_vs_dogs_small_1.h5')\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hxZUuAeAv-Do"
      },
      "source": [
        "Выберем изображение, которое сеть не видела"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4hC_1sCMwBX_"
      },
      "source": [
        "img_path = '/content/drive/My Drive/StudyingKeras/Dogs_vs_Cats/partial_data/test/cats/cat.1700.jpg'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kM-0aKO5wx2w"
      },
      "source": [
        "Визуализация изображения"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6Dz_v5ZpxARc"
      },
      "source": [
        "from keras.preprocessing import image\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "img = image.load_img(img_path, target_size=(150,150))\n",
        "# преобразуем картинки в 4мерный тензор\n",
        "img_tensor = image.img_to_array(img)\n",
        "# добавление еще одной оси спереди тензора\n",
        "img_tensor = np.expand_dims(img_tensor, axis=0)\n",
        "img_tensor /= 255\n",
        "\n",
        "# форма тензора - (1, 150, 150, 3)\n",
        "print(img_tensor.shape)\n",
        "\n",
        "plt.imshow(img_tensor[0])\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C3S8m7Twybz7"
      },
      "source": [
        "Создадим свою модель, обладающую несколькими выходами"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oCcZRK1PygwM"
      },
      "source": [
        "# класс Model() принимает два параметра:\n",
        "# 1) Входной (ые) тензор\n",
        "# 2) Выходной (ые) тензор\n",
        "# отличительная черта от Sequantial() - может иметь несколько выходов\n",
        "from keras.models import Model\n",
        "\n",
        "# извлечение вывода верхних восьми слоев\n",
        "layer_outputs = [layer.output for layer in model.layers[:8]]\n",
        "# входные данные такие же, а выходные - новые\n",
        "activation_model = Model(inputs=model.input, outputs=layer_outputs)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZJ-uXAQMzoF5"
      },
      "source": [
        "Запуск модели в режиме прогнозирования"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_z93J8jAzrjp"
      },
      "source": [
        "activations = activation_model.predict(img_tensor)\n",
        "\n",
        "# возьмем активацию первого слоя\n",
        "first_layer_activation = activations[0]\n",
        "print(first_layer_activation.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mofJBH4L0Jac"
      },
      "source": [
        "Визуализация четвертого канала предсказаний первого слоя модели"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s5b1rNjp0MsP"
      },
      "source": [
        "plt.clf()\n",
        "plt.imshow(first_layer_activation[0, :, :, 4], cmap='viridis')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "38YWCqSA1fXk"
      },
      "source": [
        "Теперь создадим полную визуализацию всех 32 каналов на каждой из 8ми карт активации\n",
        "\n",
        "Чем ниже картинки - тем глубже слой сети\n",
        "\n",
        "Чем глубже слой сети - тем более абстрактные у него активации\n",
        "\n",
        "Например, первый слой (верхняя картинка) может находить какие-то прямые, линии и т.д, а последний слой (нижняя картинка) активируется такими вещами как \"ухо\" или \"глаз\" поэтому и пиксели на изображении там, где уши или глаза\n",
        "\n",
        "По сути, человек воспринимает мир так же. Если вас попросить нарисовать велосипед, то вы нарисуете пару палок и колеса, а не все делати механизмов. То \n",
        "есть вы запоминаете только самые важные части. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4oFl3SpA2C_K"
      },
      "source": [
        "def visualise_features_maps():\n",
        "  plt.clf()\n",
        "  layer_names = []\n",
        "  # извлекаем имена слоев, чтобы потом отобразить их на рисунках\n",
        "  for layer in model.layers:\n",
        "    layer_names.append(layer.name)\n",
        "  # так как карта признаков извлекает 32 * k признаков, то берем число, которому\n",
        "  # 32 кратно просто для красоты\n",
        "  images_per_row = 16\n",
        "  for layer_name, layer_activation in zip(layer_names, activations):\n",
        "    # карта признаков имеет форму (1, size, size, n_features)\n",
        "    # берем только последнюю ось тензора\n",
        "    n_features = layer_activation.shape[-1]\n",
        "    # берем только первую ось тензора\n",
        "    size = layer_activation.shape[1]\n",
        "\n",
        "    # количество строчек в таблице отображений\n",
        "    n_cols = n_features // images_per_row\n",
        "    # сама таблица инициализируется нулями\n",
        "    display_grid = np.zeros((size * n_cols, size * images_per_row))\n",
        "\n",
        "    # обычный вложенный цикл, как в двумерной матрице\n",
        "    for col in range(n_cols):\n",
        "      for row in range(images_per_row):\n",
        "        # это - каждый маленький квадрат в таблице отображений\n",
        "        # берется каждый признак из последней оси активации (которая кратна 32)\n",
        "        channel_image = layer_activation[0, :, :, col * images_per_row + row]\n",
        "        # обработка изображения для приемлимого вида\n",
        "        channel_image -= channel_image.mean()\n",
        "        channel_image /= channel_image.std()\n",
        "        channel_image *= 64\n",
        "        channel_image += 128\n",
        "        channel_image = np.clip(channel_image, 0, 255).astype('uint8')\n",
        "        display_grid[col * size : (col + 1) * size, row * size : (row + 1) * size] = channel_image\n",
        "    \n",
        "    # size - размер каждого квадратного изображения без уменьшения\n",
        "    scale = 1. / size\n",
        "    # уменьшаем размер общей сетки отображений, чтобы все картинки поместились на ней\n",
        "    plt.figure(figsize=(scale * display_grid.shape[1], scale * display_grid.shape[0]))\n",
        "    plt.title(layer_name)\n",
        "    plt.grid(False)\n",
        "    plt.imshow(display_grid, aspect='auto', cmap='viridis')\n",
        "\n",
        "visualise_features_maps()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4KSyJbW6-zQ2"
      },
      "source": [
        "# ЧАСТЬ 2: ВИЗУАЛИЗАЦИЯ ФИЛЬТРОВ СЛОЕВ"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9gTQgVzFASL6"
      },
      "source": [
        "Надо отобразить шаблон, за который отвечает каждый фильтр, для этого:\n",
        "\n",
        "\n",
        "1.   Создадим функцию потерь, максимизирующую значение данного фильтра данного слов\n",
        "2.   С помощью СГС настроим ВХОДНОЕ изображение так, чтобы оно максимизировало данную функцию активации\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YXsCwe8NArBZ"
      },
      "source": [
        "Определение тензора потерь для визуализации фильтра"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-nhJopIuAwwB"
      },
      "source": [
        "from keras.applications import VGG16\n",
        "from keras import backend as K\n",
        "import tensorflow as tf\n",
        "tf.compat.v1.disable_eager_execution()\n",
        "\n",
        "model = VGG16(\n",
        "    weights='imagenet',\n",
        "    include_top=False\n",
        ")\n",
        "\n",
        "layer_name = 'block3_conv1'\n",
        "filter_index = 0\n",
        "\n",
        "layer_output = model.get_layer(layer_name).output\n",
        "loss = K.mean(layer_output[:, :, :, filter_index])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aih8jtSu7p4m"
      },
      "source": [
        "Получение градиента потерь относительно входа модели"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2B_taPHh71Cr"
      },
      "source": [
        "import tensorflow as tf\n",
        "# gradients возвращает список тензоров, сохраняется только первый\n",
        "grads = K.gradients(loss, model.input)[0]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UkUZHVkF8m4Q"
      },
      "source": [
        "Нормализация градиентного тензора\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qi_QK9E08p6V"
      },
      "source": [
        "# чтобы гарантировать то, что величина изменений во входном изображении\n",
        "# будет находиться в одном диапозоне, можно разделить градиентный тензор\n",
        "# на квадратный корень из усредненных квадратов значений в тензоре\n",
        "# в конце добавляем очень маленькое число, чтобы предотвратить деление на ноль\n",
        "# если вдруг дробь будет нулевая\n",
        "grads /= (K.sqrt(K.mean(K.square(grads))) + 1e-5) "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jICdOc6A9-nz"
      },
      "source": [
        "Вычисление тензора потерь и тензора градиента для заданного входного изображения"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eerfK5Ru9-VX"
      },
      "source": [
        "# мы создаем вручную свою функцию, которая затем может быть использована в Keras\n",
        "# документация - https://www.tensorflow.org/api_docs/python/tf/keras/backend/function\n",
        "# принимает массив входных тензоров\n",
        "# возвращает массив из двух выходных тензоров\n",
        "iterate =  K.function([model.input], [loss, grads])\n",
        "loss_value, grads_value = iterate([np.zeros((1, 150, 150, 3))])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lU2hHWvg_GS8"
      },
      "source": [
        "Максимизация потерь стохастическим градиентным спуском"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d41sJQTb_K-a"
      },
      "source": [
        "# начальное изображение с черно-белым шумом\n",
        "# создается случайно (через рандомные floatы)\n",
        "input_image_data = np.random.random((1, 150, 150, 3)) * 20 + 128\n",
        "# величина каждого изменения градиента\n",
        "step = 1\n",
        "# 40 шагов градиентного восхождения\n",
        "for i in range(40):\n",
        "  # вычисление значений потерь и градиента\n",
        "  loss_value, grads_value = iterate([input_image_data])\n",
        "  # корректировка входного изображения в направлении максимизации потерь\n",
        "  input_image_data += grads_value * step"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LiKIRXBMAlq5"
      },
      "source": [
        "Теперь тензор необходимо превратить в изображение"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "deHGa20GApMq"
      },
      "source": [
        "def deprocess_image(x):\n",
        "  # нормализация: получается тензор со средним значением 0 и стандартным откло\n",
        "  # нением 0.1\n",
        "  x -= x.mean()\n",
        "  x /= (x.std() + 1e-5)\n",
        "  x *= 0.1\n",
        "  x += 0.5\n",
        "  # ограничиваем значения диапозоном от 0 до 1 \n",
        "  # Функция clip() ограниченичивает элементы массива указанным интервалом\n",
        "  # допустимых значений. Например, если указать интервал [5, 10], то все \n",
        "  # значения в массиве, которые меньше 5 примут значение равное 5, а все \n",
        "  # значения больше 10, будут равны 10.\n",
        "  x = np.clip(x, 0, 1)\n",
        "  x *= 255\n",
        "  # преобразование в массив значений RGB\n",
        "  x = np.clip(x, 0, 255).astype('uint8')\n",
        "  return x"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9xmW6-GIDodc"
      },
      "source": [
        "Объединю все выше показанное в одну функию\n",
        "\n",
        "Функция генерирует изображение, которое представляет фильтр\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r4o51MpuDsex"
      },
      "source": [
        "# функция принимает имя слоя и индекс фильтра\n",
        "# функция возвращает тензор с допустимым изображением, представляющим \n",
        "# собой шаблон, который максимизирует активацию данного фильтра\n",
        "def generate_pattern(layer_name, filter_index, size=150):\n",
        "  layer_output = model.get_layer(layer_name).output\n",
        "  loss = K.mean(layer_output[:, :, :, filter_index])\n",
        "  grads = K.gradients(loss, model.input)[0]\n",
        "  grads /= (K.sqrt(K.mean(K.square(grads))) + 1e-5) \n",
        "  iterate =  K.function([model.input], [loss, grads])\n",
        "  input_image_data = np.random.random((1, 150, 150, 3)) * 20 + 128\n",
        "  step = 1\n",
        "  for i in range(40):\n",
        "    loss_value, grads_value = iterate([input_image_data])\n",
        "    input_image_data += grads_value * step\n",
        "  img = input_image_data[0]\n",
        "  return deprocess_image(img)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8B_JL6tdaUWV"
      },
      "source": [
        "generated_image = generate_pattern('block3_conv1', 0)\n",
        "plt.imshow(generated_image)\n",
        "\n",
        "# похоже, что фильтр с индексом 0 в слое отвечает за узор \"в горошек\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ux7r8yjqMYDS"
      },
      "source": [
        "Вывод откликов всех фильтров в указанном слое"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jygRK1e-Mekl"
      },
      "source": [
        "layer_name = 'block3_conv1'\n",
        "size = 150\n",
        "\n",
        "plt.clf()\n",
        "\n",
        "for i in range(8):\n",
        "  for j in range(8):\n",
        "    filter_img = generate_pattern(layer_name, i + (j * 8), size=size)\n",
        "    plt.figure(i + j)\n",
        "    imgplot = plt.imshow(filter_img)\n",
        "  \n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bUCJ0hqagvIp"
      },
      "source": [
        "# ЧАСТЬ 3: ВИЗУАЛИЗАЦИЯ ТЕПЛОВЫХ КАРТ АКТИВАЦИИ СЛОЕВ"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rYHssXSCquim"
      },
      "source": [
        "Тепловая карта признаков - карта признаков, которая обозначает \"как интенсивно входное изображение активирует класс\"\n",
        "\n",
        "Определяет насколько важно каждое местоположение на картинке для каждого класса\n",
        "\n",
        "Производится взвешивание признаков в пространственной карте \"как интенсивно входное изображение активирует каналы\" по категории \"насколько важен каждый\n",
        "канал для класса\""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Nl6tRNJ7rkNj"
      },
      "source": [
        "from keras.applications.vgg16 import VGG16\n",
        "\n",
        "# полносвязный классификатор НЕ удаляется, как в прошлых случаях\n",
        "model = VGG16(weights='imagenet')\n",
        "model._make_predict_function()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mLMjota_xzn0"
      },
      "source": [
        "Предобработка изображения "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NLcPa2glx3UT"
      },
      "source": [
        "from keras.preprocessing import image\n",
        "from keras.applications.vgg16 import preprocess_input, decode_predictions\n",
        "import numpy as np\n",
        "\n",
        "img_path = '/content/drive/My Drive/StudyingKeras/FeaturesVisualisation/elephants.PNG'\n",
        "\n",
        "img = image.load_img(img_path, target_size=(224, 224))\n",
        "# переводим изображение в массив numpy (224, 224, 3)\n",
        "x = image.img_to_array(img)\n",
        "# увеличиваем размерность на 1 (1, 224, 224, 3)\n",
        "x = np.expand_dims(x, axis=0)\n",
        "# нормализация пакетов цвета\n",
        "x = preprocess_input(x)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1Bi7yfrzy6DG"
      },
      "source": [
        "Предсказание на изображении"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7Z35o6V7y-dq"
      },
      "source": [
        "preds = model.predict(x)\n",
        "# decode_predictions возвращает массив массивов классов, которые были распознаны \n",
        "# на данной фотографии с наибольшей вероятностью (класс, описание, вероятность)\n",
        "# лучшие предсказания: африканский слон, кабан-секач, индийский слон\n",
        "print(f\"Predicted here: \\n {decode_predictions(preds, top=3)}\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-k8v0P4W0ym6"
      },
      "source": [
        "Выведем класс с наибольшей вероятностью"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yD24oQsl0vyM"
      },
      "source": [
        "print(f'Class number is {np.argmax(preds[0])}')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nBfweVlx08XF"
      },
      "source": [
        "Реализация алгоритма Grad_CAM"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m65D3XjS1FOi"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf\n",
        "tf.compat.v1.disable_eager_execution()\n",
        "\n",
        "import keras.backend as K\n",
        "# выведем часть иображения, которая наиболее близко напоминает африканского слона\n",
        "# [:, 386] выведет 386 столбец из дмумерного тензора, например:\n",
        "# line = [[1 2 3]\n",
        "#         [4 5 6]]\n",
        "# line[:,2] = [3 6]\n",
        "\n",
        "african_elephant_output = model.output[:, 386]\n",
        "# выходная карта последнего сверточного слоя\n",
        "last_conv_layer_map = model.get_layer('block5_conv3')\n",
        "# градиент класса \"африканский слон\" для выходной карты признаков последнего слоя\n",
        "grads = K.gradients(african_elephant_output, last_conv_layer_map.output)[0]\n",
        "# вектор формы (512,) каждый элемент которого определяет интенсивность\n",
        "# градиента для заданного канала в карте признаков\n",
        "pooled_grads = K.mean(grads, axis=(0, 1, 2))\n",
        "\n",
        "# function - очень хитрая вещь\n",
        "# мы в параметрах указываем переменные КОТОРЫЕ УЖЕ СОЗДАНЫ\n",
        "# она понимает СВЯЗЬ между ними, и какие действия нужно сделать\n",
        "# поэтому если вместо model мы создадим model_1 и поместим в функцию,\n",
        "# то она для НОВОЙ модели посчитает градиенты и выход последнего слоя и возвратит\n",
        "iterate = K.function(inputs=[model.input], outputs=[pooled_grads, last_conv_layer_map.output[0]])\n",
        "\n",
        "pooled_grads_value, conv_layer_output_value = iterate([x])\n",
        "\n",
        "for i in range(512):\n",
        "  # умножение каждого канала на \"важность\" этого канада для класса \"афр.слон\"\n",
        "  conv_layer_output_value[:, :, i] *= pooled_grads_value[i]\n",
        "\n",
        "# среднее для каналов признаков - и есть тепловая карта активации\n",
        "heatmap = np.mean(conv_layer_output_value, axis=-1)\n",
        "\n",
        "# нормализация тепловой карты\n",
        "# для примера: np.maximum([[0, 1, -5][-9, 3, 5]) = [0, 3, 5]\n",
        "heatmap = np.maximum(heatmap, 0)\n",
        "heatmap /= np.max(heatmap)\n",
        "plt.clf()\n",
        "plt.matshow(heatmap)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zImclvLmErRO"
      },
      "source": [
        "Наложим тепловую карту на исходное изображение и выведем его"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "inTc1Z7zFVXt"
      },
      "source": [
        "import cv2\n",
        "from google.colab.patches import cv2_imshow\n",
        "\n",
        "img = cv2.imread(img_path)\n",
        "heatmap = cv2.resize(heatmap, (img.shape[1], img.shape[0]))\n",
        "# преобразование тепловой карты в RGB\n",
        "heatmap = np.uint8(255 * heatmap)\n",
        "heatmap = cv2.applyColorMap(heatmap, cv2.COLORMAP_JET)\n",
        "img = heatmap * 0.6 + img\n",
        "cv2_imshow(img)\n",
        "\n",
        "# мы видим, что уши слоненка сильно активированы\n",
        "# видимо, именно по ним сеть и приняла решение, что на фото - слоны"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}
